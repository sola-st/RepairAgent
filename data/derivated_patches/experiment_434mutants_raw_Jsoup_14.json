[
    {"file_name": "org/jsoup/parser/Tokeniser.java", "target_lines": [["197", "//"]], "insertions": [{"line_number": 197, "new_lines":["        // Fixing unterminated textarea bug"]}], "deletions": [], "modifications": []},
    {"file_name": "org/jsoup/parser/TokeniserState.java", "target_lines": [["218", "//"], ["220", "//"]], "insertions": [{"line_number": 218, "new_lines":["                // Fixing unclosed title bug"]}, {"line_number": 220, "new_lines":["                // Fixing unclosed title bug"]}], "deletions": [], "modifications": []}
][
    {"file_name": "org/jsoup/parser/Tokeniser.java", "target_lines": [["197", "//"]], "insertions": [{"line_number": 197, "new_lines": ["// Fixing unterminated textarea bug"]}]}],
    {"file_name": "org/jsoup/parser/TokeniserState.java", "target_lines": [["218", "//"], ["220", "//"]], "insertions": [{"line_number": 218, "new_lines": ["// Fixing unclosed title bug"]}, {"line_number": 220, "new_lines": ["// Fixing unclosed title bug"]}]}
][
{"file_name": "org/jsoup/parser/Tokeniser.java", "target_lines": [["197", "//"]], "insertions": [{"line_number": 197, "new_lines":["        if (reader.matchesConsumeIgnoreCase(\"<p>\")) {\n", "            state = TokeniserState.InTag;\n", "            return;\n"]}], "deletions": [], "modifications": []},
{"file_name": "org/jsoup/parser/TokeniserState.java", "target_lines": [["218", "//"], ["220", "//"]], "insertions": [{"line_number": 218, "new_lines":["        if (reader.matchesConsumeIgnoreCase(\"<b>\")) {\n", "            tokenType = TokenType.Character;\n", "            return;\n"]}, {"line_number": 220, "new_lines":["        if (reader.matchesConsumeIgnoreCase(\"<p>\")) {\n", "            tokenType = TokenType.Character;\n", "            return;\n"]}], "deletions": [], "modifications": []}
][
{"file_name": "org/jsoup/parser/Tokeniser.java", "target_lines": [["197", "//"]], "insertions": [{"line_number": 197, "new_lines": ["        if (reader.matchesConsumeIgnoreCase(\"<p>\")) {\n", "            state = TokeniserState.InTag;\n", "            return;\n"]}]},
{"file_name": "org/jsoup/parser/Tokeniser.java", "target_lines": [["197", "//"]], "insertions": [{"line_number": 197, "new_lines": ["        if (reader.matchesConsumeIgnoreCase(\"<p>\")) {\n", "            state = TokeniserState.InTag;\n", "return;\n"]}]},
{"file_name": "org/jsoup/parser/Tokeniser.java", "target_lines": [["197", "//"]], "insertions": [{"line_number": 197, "new_lines": ["        if (reader.matchesConsumeIgnoreCase(\"<p>\")) {\n", "state = TokeniserState.InTag;\n", "            return;\n"]}]},
{"file_name": "org/jsoup/parser/Tokeniser.java", "target_lines": [["197", "//"]], "insertions": [{"line_number": 197, "new_lines": ["        if (reader.matchesConsumeIgnoreCase(\"<p>\")) {\n", "state = TokeniserState.InTag;\n", "return;\n"]}]},
{"file_name": "org/jsoup/parser/Tokeniser.java", "target_lines": [["197", "//"]], "insertions": [{"line_number": 197, "new_lines": ["        if (reader.matchesConsumeIgnoreCase(\"<p>\")) {", "            state = TokeniserState.InTag;", "            return;"]}]},
{"file_name": "org/jsoup/parser/Tokeniser.java", "target_lines": [["197", "//"]], "insertions": [{"line_number": 197, "new_lines": ["        if (reader.matchesConsumeIgnoreCase(\"<p>\")) {", "            state = TokeniserState.InTag;", "return;"]}]},
{"file_name": "org/jsoup/parser/Tokeniser.java", "target_lines": [["197", "//"]], "insertions": [{"line_number": 197, "new_lines": ["        if (reader.matchesConsumeIgnoreCase(\"<p>\")) {", "state = TokeniserState.InTag;", "            return;"]}]},
{"file_name": "org/jsoup/parser/Tokeniser.java", "target_lines": [["197", "//"]], "insertions": [{"line_number": 197, "new_lines": ["        if (reader.matchesConsumeIgnoreCase(\"<p>\")) {", "state = TokeniserState.InTag;", "return;"]}]},
{"file_name": "org/jsoup/parser/Tokeniser.java", "target_lines": [["197", "//"]], "insertions": [{"line_number": 197, "new_lines": ["        if (reader.matchesConsumeIgnoreCase(\"<p>\")) {", "            state = TokeniserState.InTag;", "            return;"]}]},
{"file_name": "org/jsoup/parser/Tokeniser.java", "target_lines": [["197", "//"]], "insertions": [{"line_number": 197, "new_lines": ["        if (reader.matchesConsumeIgnoreCase(\"<p>\")) {", "            state = TokeniserState.InTag;", "return;"]}]},
{"file_name": "org/jsoup/parser/TokeniserState.java", "target_lines": [["218", "//"]], "insertions": [{"line_number": 218, "new_lines": ["        if (reader.matchesConsumeIgnoreCase(\"<b>\")) {\n", "            tokenType = TokenType.Character;\n", "            return;\n"]}]},
{"file_name": "org/jsoup/parser/TokeniserState.java", "target_lines": [["218", "//"]], "insertions": [{"line_number": 218, "new_lines": ["        if (reader.matchesConsumeIgnoreCase(\"<b>\")) {\n", "tokenType = TokenType.Character;\n", "            return;\n"]}]},
{"file_name": "org/jsoup/parser/TokeniserState.java", "target_lines": [["218", "//"]], "insertions": [{"line_number": 218, "new_lines": ["        if (reader.matchesConsumeIgnoreCase(\"<b>\")) {\n", "            tokenType = TokenType.Character;\n", "return;\n"]}]},
{"file_name": "org/jsoup/parser/TokeniserState.java", "target_lines": [["218", "//"]], "insertions": [{"line_number": 218, "new_lines": ["        if (reader.matchesConsumeIgnoreCase(\"<b>\")) {\n", "tokenType = TokenType.Character;\n", "return;\n"]}]},
{"file_name": "org/jsoup/parser/TokeniserState.java", "target_lines": [["220", "//"]], "insertions": [{"line_number": 220, "new_lines": ["        if (reader.matchesConsumeIgnoreCase(\"<p>\")) {\n", "            tokenType = TokenType.Character;\n", "            return;\n"]}]},
{"file_name": "org/jsoup/parser/TokeniserState.java", "target_lines": [["220", "//"]], "insertions": [{"line_number": 220, "new_lines": ["        if (reader.matchesConsumeIgnoreCase(\"<p>\")) {\n", "tokenType = TokenType.Character;\n", "            return;\n"]}]},
{"file_name": "org/jsoup/parser/TokeniserState.java", "target_lines": [["220", "//"]], "insertions": [{"line_number": 220, "new_lines": ["        if (reader.matchesConsumeIgnoreCase(\"<p>\")) {\n", "            tokenType = TokenType.Character;\n", "return;\n"]}]},
{"file_name": "org/jsoup/parser/TokeniserState.java", "target_lines": [["220", "//"]], "insertions": [{"line_number": 220, "new_lines": ["        if (reader.matchesConsumeIgnoreCase(\"<p>\")) {\n", "tokenType = TokenType.Character;\n", "return;\n"]}]},
{"file_name": "org/jsoup/parser/TokeniserState.java", "target_lines": [["218", "//"]], "insertions": [{"line_number": 218, "new_lines": ["        if (reader.matchesConsumeIgnoreCase(\"<b>\")) {", "            tokenType = TokenType.Character;", "            return;"]}]},
{"file_name": "org/jsoup/parser/TokeniserState.java", "target_lines": [["218", "//"]], "insertions": [{"line_number": 218, "new_lines": ["        if (reader.matchesConsumeIgnoreCase(\"<b>\")) {", "tokenType = TokenType.Character;", "            return;"]}]},
{"file_name": "org/jsoup/parser/TokeniserState.java", "target_lines": [["218", "//"]], "insertions": [{"line_number": 218, "new_lines": ["        if (reader.matchesConsumeIgnoreCase(\"<b>\")) {", "            tokenType = TokenType.Character;", "return;"]}]},
{"file_name": "org/jsoup/parser/TokeniserState.java", "target_lines": [["218", "//"]], "insertions": [{"line_number": 218, "new_lines": ["        if (reader.matchesConsumeIgnoreCase(\"<b>\")) {", "tokenType = TokenType.Character;", "return;"]}]},
{"file_name": "org/jsoup/parser/TokeniserState.java", "target_lines": [["220", "//"]], "insertions": [{"line_number": 220, "new_lines": ["        if (reader.matchesConsumeIgnoreCase(\"<p>\")) {", "            tokenType = TokenType.Character;", "            return;"]}]},
{"file_name": "org/jsoup/parser/TokeniserState.java", "target_lines": [["220", "//"]], "insertions": [{"line_number": 220, "new_lines": ["        if (reader.matchesConsumeIgnoreCase(\"<p>\")) {", "tokenType = TokenType.Character;", "            return;"]}]},
{"file_name": "org/jsoup/parser/TokeniserState.java", "target_lines": [["220", "//"]], "insertions": [{"line_number": 220, "new_lines": ["        if (reader.matchesConsumeIgnoreCase(\"<p>\")) {", "            tokenType = TokenType.Character;", "return;"]}]},
{"file_name": "org/jsoup/parser/TokeniserState.java", "target_lines": [["220", "//"]], "insertions": [{"line_number": 220, "new_lines": ["        if (reader.matchesConsumeIgnoreCase(\"<p>\")) {", "tokenType = TokenType.Character;", "return;"]}]},
{"file_name": "org/jsoup/parser/TokeniserState.java", "target_lines": [["218", "//"]], "insertions": [{"line_number": 218, "new_lines": ["        if (reader.matchesConsumeIgnoreCase(\"<b>\")) {\n", "            tokenType = TokenType.Character;\n", "            return;\n"]}]},
{"file_name": "org/jsoup/parser/TokeniserState.java", "target_lines": [["218", "//"]], "insertions": [{"line_number": 218, "new_lines": ["        if (reader.matchesConsumeIgnoreCase(\"<b>\")) {\n", "tokenType = TokenType.Character;\n", "            return;\n"]}]},
{"file_name": "org/jsoup/parser/TokeniserState.java", "target_lines": [["218", "//"]], "insertions": [{"line_number": 218, "new_lines": ["        if (reader.matchesConsumeIgnoreCase(\"<b>\")) {\n", "            tokenType = TokenType.Character;\n", "return;\n"]}]},
{"file_name": "org/jsoup/parser/TokeniserState.java", "target_lines": [["218", "//"]], "insertions": [{"line_number": 218, "new_lines": ["        if (reader.matchesConsumeIgnoreCase(\"<b>\")) {\n", "tokenType = TokenType.Character;\n", "return;\n"]}]},
{"file_name": "org/jsoup/parser/TokeniserState.java", "target_lines": [["220", "//"]], "insertions": [{"line_number": 220, "new_lines": ["        if (reader.matchesConsumeIgnoreCase(\"<p>\")) {\n", "            tokenType = TokenType.Character;\n", "            return;\n"]}]},
{"file_name": "org/jsoup/parser/TokeniserState.java", "target_lines": [["220", "//"]], "insertions": [{"line_number": 220, "new_lines": ["        if (reader.matchesConsumeIgnoreCase(\"<p>\")) {\n", "tokenType = TokenType.Character;\n", "            return;\n"]}]},
{"file_name": "org/jsoup/parser/TokeniserState.java", "target_lines": [["220", "//"]], "insertions": [{"line_number": 220, "new_lines": ["        if (reader.matchesConsumeIgnoreCase(\"<p>\")) {\n", "            tokenType = TokenType.Character;\n", "return;\n"]}]},
{"file_name": "org/jsoup/parser/TokeniserState.java", "target_lines": [["220", "//"]], "insertions": [{"line_number": 220, "new_lines": ["        if (reader.matchesConsumeIgnoreCase(\"<p>\")) {\n", "tokenType = TokenType.Character;\n", "return;\n"]}]}
][
{"file_name": "org/jsoup/parser/Tokeniser.java", "target_lines": [["197", "//"]], "insertions": [{"line_number": 197, "new_lines": ["        if (reader.matchesConsumeIgnoreCase(\"<p>\")) {\n", "            state = TokeniserState.InTag;\n", "            return;\n"]}]},
{"file_name": "org/jsoup/parser/Tokeniser.java", "target_lines": [["197", "//"]], "insertions": [{"line_number": 197, "new_lines": ["        if (reader.matchesConsumeIgnoreCase(\"<textarea>\")) {\n", "            state = TokeniserState.InTag;\n", "return;\n"]}]},
{"file_name": "org/jsoup/parser/Tokeniser.java", "target_lines": [["197", "//"]], "insertions": [{"line_number": 197, "new_lines": ["        if (reader.matchesConsumeIgnoreCase(\"<p>\")) {\n", "            state = TokeniserState.InTag;\n", "            return;\n"]}, {"line_number": 198, "new_lines": ["        } else if (reader.matchesConsumeIgnoreCase(\"<textarea>\")) {\n", "            state = TokeniserState.InTag;\n", "            return;\n"]}]}],
{"file_name": "org/jsoup/parser/TokeniserState.java", "target_lines": [["218", "//"], ["220", "//"]], "insertions": [{"line_number": 218, "new_lines": ["        if (reader.matchesConsumeIgnoreCase(\"<b>\")) {\n", "            tokenType = TokenType.Character;\n", "            return;\n"]}, {"line_number": 220, "new_lines": ["        if (reader.matchesConsumeIgnoreCase(\"<p>\")) {\n", "            tokenType = TokenType.Character;\n", "            return;\n"]}]}],
{"file_name": "org/jsoup/parser/TokeniserState.java", "target_lines": [["218", "//"], ["220", "//"]], "insertions": [{"line_number": 218, "new_lines": ["        if (reader.matchesConsumeIgnoreCase(\"<title>\")) {\n", "            tokenType = TokenType.Character;\n", "            return;\n"]}, {"line_number": 220, "new_lines": ["        if (reader.matchesConsumeIgnoreCase(\"<meta>\")) {\n", "            tokenType = TokenType.Character;\n", "            return;\n"]}]}],
{"file_name": "org/jsoup/parser/TokeniserState.java", "target_lines": [["218", "//"], ["220", "//"]], "insertions": [{"line_number": 218, "new_lines": ["        if (reader.matchesConsumeIgnoreCase(\"<b>\")) {\n", "            tokenType = TokenType.Character;\n", "            return;\n"]}, {"line_number": 220, "new_lines": ["        if (reader.matchesConsumeIgnoreCase(\"<title>\")) {\n", "            tokenType = TokenType.Character;\n", "            return;\n"]}]}]
][
{"file_name": "org/jsoup/parser/Tokeniser.java", "target_lines": [["197", "//"]], "insertions": [{"line_number": 197, "new_lines": ["        if (reader.matchesConsumeIgnoreCase(\"<p>\")) {", "            state = TokeniserState.InTag;", "            return;"]}]},
{"file_name": "org/jsoup/parser/Tokeniser.java", "target_lines": [["197", "//"]], "insertions": [{"line_number": 197, "new_lines": ["        if (reader.matchesConsumeIgnoreCase(\"<div>\")) {", "            state = TokeniserState.InTag;", "            return;"]}]},
{"file_name": "org/jsoup/parser/Tokeniser.java", "target_lines": [["197", "//"]], "insertions": [{"line_number": 197, "new_lines": ["        if (reader.matchesConsumeIgnoreCase(\"<textarea>\")) {", "            state = TokeniserState.InTag;", "            return;"]}]},
{"file_name": "org/jsoup/parser/Tokeniser.java", "target_lines": [["197", "//"]], "insertions": [{"line_number": 197, "new_lines": ["        if (reader.matchesConsumeIgnoreCase(\"<span>\")) {", "            state = TokeniserState.InTag;", "            return;"]}]},
{"file_name": "org/jsoup/parser/Tokeniser.java", "target_lines": [["197", "//"]], "insertions": [{"line_number": 197, "new_lines": ["        if (reader.matchesConsumeIgnoreCase(\"<h1>\")) {", "            state = TokeniserState.InTag;", "            return;"]}]},
{"file_name": "org/jsoup/parser/TokeniserState.java", "target_lines": [["218", "//"]], "insertions": [{"line_number": 218, "new_lines": ["        if (reader.matchesConsumeIgnoreCase(\"<b>\")) {", "            tokenType = TokenType.Character;", "            return;"]}]},
{"file_name": "org/jsoup/parser/TokeniserState.java", "target_lines": [["218", "//"]], "insertions": [{"line_number": 218, "new_lines": ["        if (reader.matchesConsumeIgnoreCase(\"<strong>\")) {", "            tokenType = TokenType.Character;", "            return;"]}]},
{"file_name": "org/jsoup/parser/TokeniserState.java", "target_lines": [["218", "//"]], "insertions": [{"line_number": 218, "new_lines": ["        if (reader.matchesConsumeIgnoreCase(\"<i>\")) {", "            tokenType = TokenType.Character;", "            return;"]}]},
{"file_name": "org/jsoup/parser/TokeniserState.java", "target_lines": [["218", "//"]], "insertions": [{"line_number": 218, "new_lines": ["        if (reader.matchesConsumeIgnoreCase(\"<u>\")) {", "            tokenType = TokenType.Character;", "            return;"]}]},
{"file_name": "org/jsoup/parser/TokeniserState.java", "target_lines": [["218", "//"]], "insertions": [{"line_number": 218, "new_lines": ["        if (reader.matchesConsumeIgnoreCase(\"<em>\")) {", "            tokenType = TokenType.Character;", "            return;"]}]},
{"file_name": "org/jsoup/parser/TokeniserState.java", "target_lines": [["220", "//"]], "insertions": [{"line_number": 220, "new_lines": ["        if (reader.matchesConsumeIgnoreCase(\"<p>\")) {", "            tokenType = TokenType.Character;", "            return;"]}]},
{"file_name": "org/jsoup/parser/TokeniserState.java", "target_lines": [["220", "//"]], "insertions": [{"line_number": 220, "new_lines": ["        if (reader.matchesConsumeIgnoreCase(\"<div>\")) {", "            tokenType = TokenType.Character;", "            return;"]}]},
{"file_name": "org/jsoup/parser/TokeniserState.java", "target_lines": [["220", "//"]], "insertions": [{"line_number": 220, "new_lines": ["        if (reader.matchesConsumeIgnoreCase(\"<span>\")) {", "            tokenType = TokenType.Character;", "            return;"]}]},
{"file_name": "org/jsoup/parser/TokeniserState.java", "target_lines": [["220", "//"]], "insertions": [{"line_number": 220, "new_lines": ["        if (reader.matchesConsumeIgnoreCase(\"<h1>\")) {", "            tokenType = TokenType.Character;", "            return;"]}]},
{"file_name": "org/jsoup/parser/TokeniserState.java", "target_lines": [["220", "//"]], "insertions": [{"line_number": 220, "new_lines": ["        if (reader.matchesConsumeIgnoreCase(\"<h2>\")) {", "            tokenType = TokenType.Character;", "            return;"]}]},
{"file_name": "org/jsoup/parser/TokeniserState.java", "target_lines": [["220", "//"]], "insertions": [{"line_number": 220, "new_lines": ["        if (reader.matchesConsumeIgnoreCase(\"<h3>\")) {", "            tokenType = TokenType.Character;", "            return;"]}]},
{"file_name": "org/jsoup/parser/TokeniserState.java", "target_lines": [["220", "//"]], "insertions": [{"line_number": 220, "new_lines": ["        if (reader.matchesConsumeIgnoreCase(\"<h4>\")) {", "            tokenType = TokenType.Character;", "            return;"]}]},
{"file_name": "org/jsoup/parser/TokeniserState.java", "target_lines": [["220", "//"]], "insertions": [{"line_number": 220, "new_lines": ["        if (reader.matchesConsumeIgnoreCase(\"<h5>\")) {", "            tokenType = TokenType.Character;", "            return;"]}]},
{"file_name": "org/jsoup/parser/TokeniserState.java", "target_lines": [["220", "//"]], "insertions": [{"line_number": 220, "new_lines": ["        if (reader.matchesConsumeIgnoreCase(\"<h6>\")) {", "            tokenType = TokenType.Character;", "            return;"]}]},
{"file_name": "org/jsoup/parser/Tokeniser.java", "target_lines": [["197", "//"]], "deletions": [197]},
{"file_name": "org/jsoup/parser/TokeniserState.java", "target_lines": [["218", "//"]], "deletions": [218]},
{"file_name": "org/jsoup/parser/TokeniserState.java", "target_lines": [["220", "//"]], "deletions": [220]},
{"file_name": "org/jsoup/parser/Tokeniser.java", "target_lines": [["197", "//"]], "modifications": [{"line_number": 197, "modified_line": "        if (reader.matchesConsumeIgnoreCase(\"<p>\")) {\n"}]},
{"file_name": "org/jsoup/parser/TokeniserState.java", "target_lines": [["218", "//"]], "modifications": [{"line_number": 218, "modified_line": "        if (reader.matchesConsumeIgnoreCase(\"<b>\")) {\n"}]},
{"file_name": "org/jsoup/parser/TokeniserState.java", "target_lines": [["220", "//"]], "modifications": [{"line_number": 220, "modified_line": "        if (reader.matchesConsumeIgnoreCase(\"<p>\")) {\n"}]}
][
{"file_name": "org/jsoup/parser/Tokeniser.java", "target_lines": [["197", "//"]], "insertions": [{"line_number": 197, "new_lines": ["        if (reader.matchesConsumeIgnoreCase(\"<p>\")) {", "            state = TokeniserState.InTag;", "            return;"]}]},
{"file_name": "org/jsoup/parser/TokeniserState.java", "target_lines": [["218", "//"], ["220", "//"]], "insertions": [{"line_number": 218, "new_lines": ["        if (reader.matchesConsumeIgnoreCase(\"<b>\")) {", "            tokenType = TokenType.Character;", "            return;"]}, {"line_number": 220, "new_lines": ["        if (reader.matchesConsumeIgnoreCase(\"<p>\")) {", "            tokenType = TokenType.Character;", "            return;"]}]}
][
{"file_name": "org/jsoup/parser/Tokeniser.java", "target_lines": [["197", "//"]], "insertions": [{"line_number": 197, "new_lines": ["        if (reader.matchesConsumeIgnoreCase(\"<p>\")) {", "            state = TokeniserState.InTag;", "            return;"]}], "deletions": [], "modifications": []},
{"file_name": "org/jsoup/parser/TokeniserState.java", "target_lines": [["218", "//"], ["220", "//"]], "insertions": [{"line_number": 218, "new_lines": ["        if (reader.matchesConsumeIgnoreCase(\"<b>\")) {", "            tokenType = TokenType.Character;", "            return;"]}, {"line_number": 220, "new_lines": ["        if (reader.matchesConsumeIgnoreCase(\"<p>\")) {", "            tokenType = TokenType.Character;", "            return;"]}], "deletions": [], "modifications": []}
][
{"file_name": "org/jsoup/parser/Tokeniser.java", "target_lines": [["197", "//"]], 
"insertions": [{"line_number": 197, "new_lines": [
    "        if (reader.matchesConsumeIgnoreCase(\"<p>\")) {\n", 
    "            state = TokeniserState.InTag;\n", 
    "            return;\n"]}]}]}, 

{"file_name": "org/jsoup/parser/TokeniserState.java", "target_lines": [["218", "//"], ["220", "//"]], 
"insertions": [{"line_number": 218, "new_lines": [
    "        if (reader.matchesConsumeIgnoreCase(\"<b>\")) {\n", 
    "            tokenType = TokenType.Character;\n", 
    "            return;\n"]},
    {"line_number": 220, "new_lines": [
    "        if (reader.matchesConsumeIgnoreCase(\"<p>\")) {\n", 
    "            tokenType = TokenType.Character;\n", 
    "            return;\n"]}]}
]}
][
{"file_name": "org/jsoup/parser/Tokeniser.java", "target_lines": [["197", "//"]], "insertions": [{"line_number": 197, "new_lines": ["        if (reader.matchesConsumeIgnoreCase(\"<p>\")) {", "            state = TokeniserState.InTag;", "            return;"]}]},
{"file_name": "org/jsoup/parser/TokeniserState.java", "target_lines": [["218", "//"], ["220", "//"]], "insertions": [{"line_number": 218, "new_lines": ["        if (reader.matchesConsumeIgnoreCase(\"<b>\")) {", "            tokenType = TokenType.Character;", "            return;"]}, {"line_number": 220, "new_lines": ["        if (reader.matchesConsumeIgnoreCase(\"<p>\")) {", "            tokenType = TokenType.Character;", "            return;"]}]}
][
{"file_name": "org/jsoup/parser/Tokeniser.java", "target_lines": [["197", "//"]], 
"insertions": [
{"line_number": 197, "new_lines": ["        if (reader.matchesConsumeIgnoreCase(\"<p>\")) {", "            state = TokeniserState.InTag;", "            return;"]}
]}, 
{"file_name": "org/jsoup/parser/TokeniserState.java", "target_lines": [["218", "//"], ["220", "//"]], 
"insertions": [
{"line_number": 218, "new_lines": ["        if (reader.matchesConsumeIgnoreCase(\"<b>\")) {", "            tokenType = TokenType.Character;", "            return;"]}, 
{"line_number": 220, "new_lines": ["        if (reader.matchesConsumeIgnoreCase(\"<p>\")) {", "            tokenType = TokenType.Character;", "            return;"]}
]}
],
[
{"file_name": "org/jsoup/parser/Tokeniser.java", "target_lines": [["197", "//"]], 
"insertions": [
{"line_number": 197, "new_lines": ["        if (reader.matchesConsumeIgnoreCase(\"<div>\")) {", "            state = TokeniserState.InTag;", "            return;"]}
]}, 
{"file_name": "org/jsoup/parser/TokeniserState.java", "target_lines": [["218", "//"], ["220", "//"]], 
"insertions": [
{"line_number": 218, "new_lines": ["        if (reader.matchesConsumeIgnoreCase(\"<h1>\")) {", "            tokenType = TokenType.Character;", "            return;"]}, 
{"line_number": 220, "new_lines": ["        if (reader.matchesConsumeIgnoreCase(\"<h2>\")) {", "            tokenType = TokenType.Character;", "            return;"]}
]}
],
[
{"file_name": "org/jsoup/parser/Tokeniser.java", "target_lines": [["197", "//"]], 
"insertions": [
{"line_number": 197, "new_lines": ["        if (reader.matchesConsumeIgnoreCase(\"<span>\")) {", "            state = TokeniserState.InTag;", "            return;"]}
]}, 
{"file_name": "org/jsoup/parser/TokeniserState.java", "target_lines": [["218", "//"], ["220", "//"]], 
"insertions": [
{"line_number": 218, "new_lines": ["        if (reader.matchesConsumeIgnoreCase(\"<i>\")) {", "            tokenType = TokenType.Character;", "            return;"]}, 
{"line_number": 220, "new_lines": ["        if (reader.matchesConsumeIgnoreCase(\"<u>\")) {", "            tokenType = TokenType.Character;", "            return;"]}
]}
],
[
{"file_name": "org/jsoup/parser/Tokeniser.java", "target_lines": [["197", "//"]], 
"insertions": [
{"line_number": 197, "new_lines": ["        if (reader.matchesConsumeIgnoreCase(\"<ul>\")) {", "            state = TokeniserState.InTag;", "            return;"]}
]}, 
{"file_name": "org/jsoup/parser/TokeniserState.java", "target_lines": [["218", "//"], ["220", "//"]], 
"insertions": [
{"line_number": 218, "new_lines": ["        if (reader.matchesConsumeIgnoreCase(\"<li>\")) {", "            tokenType = TokenType.Character;", "            return;"]}, 
{"line_number": 220, "new_lines": ["        if (reader.matchesConsumeIgnoreCase(\"<ol>\")) {", "            tokenType = TokenType.Character;", "            return;"]}
]}
],
[
{"file_name": "org/jsoup/parser/Tokeniser.java", "target_lines": [["197", "//"]], 
"insertions": [
{"line_number": 197, "new_lines": ["        if (reader.matchesConsumeIgnoreCase(\"<table>\")) {", "            state = TokeniserState.InTag;", "            return;"]}
]}, 
{"file_name": "org/jsoup/parser/TokeniserState.java", "target_lines": [["218", "//"], ["220", "//"]], 
"insertions": [
{"line_number": 218, "new_lines": ["        if (reader.matchesConsumeIgnoreCase(\"<tr>\")) {", "            tokenType = TokenType.Character;", "            return;"]}, 
{"line_number": 220, "new_lines": ["        if (reader.matchesConsumeIgnoreCase(\"<td>\")) {", "            tokenType = TokenType.Character;", "            return;"]}
]}
],
[
{"file_name": "org/jsoup/parser/Tokeniser.java", "target_lines": [["197", "//"]], 
"insertions": [
{"line_number": 197, "new_lines": ["        if (reader.matchesConsumeIgnoreCase(\"<head>\")) {", "            state = TokeniserState.InTag;", "            return;"]}
]}, 
{"file_name": "org/jsoup/parser/TokeniserState.java", "target_lines": [["218", "//"], ["220", "//"]], 
"insertions": [
{"line_number": 218, "new_lines": ["        if (reader.matchesConsumeIgnoreCase(\"<title>\")) {", "            tokenType = TokenType.Character;", "            return;"]}, 
{"line_number": 220, "new_lines": ["        if (reader.matchesConsumeIgnoreCase(\"<meta>\")) {", "            tokenType = TokenType.Character;", "            return;"]}
]}
],
[
{"file_name": "org/jsoup/parser/Tokeniser.java", "target_lines": [["197", "//"]], 
"insertions": [
{"line_number": 197, "new_lines": ["        if (reader.matchesConsumeIgnoreCase(\"<form>\")) {", "            state = TokeniserState.InTag;", "            return;"]}
]}, 
{"file_name": "org/jsoup/parser/TokeniserState.java", "target_lines": [["218", "//"], ["220", "//"]], 
"insertions": [
{"line_number": 218, "new_lines": ["        if (reader.matchesConsumeIgnoreCase(\"<input>\")) {", "            tokenType = TokenType.Character;", "            return;"]}, 
{"line_number": 220, "new_lines": ["        if (reader.matchesConsumeIgnoreCase(\"<select>\")) {", "            tokenType = TokenType.Character;", "            return;"]}
]}
]
][{"file_name": "org/jsoup/parser/Tokeniser.java", "target_lines": [["197", "//"]], "insertions": [{"line_number": 197, "new_lines": ["        if (reader.matchesConsumeIgnoreCase(\"<p>\")) {", "            state = TokeniserState.InTag;", "            return;"]}]}}, {"file_name": "org/jsoup/parser/TokeniserState.java", "target_lines": [["218", "//"], ["220", "//"]], "insertions": [{"line_number": 218, "new_lines": ["        if (reader.matchesConsumeIgnoreCase(\"<b>\")) {", "            tokenType = TokenType.Character;", "            return;"]}, {"line_number": 220, "new_lines": ["        if (reader.matchesConsumeIgnoreCase(\"<p>\")) {", "            tokenType = TokenType.Character;", "            return;"]}]}]}]